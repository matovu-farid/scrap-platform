import { DocsLayout } from "@/components/docs-layout";
import { CodeBlock } from "@/components/docs/code-block";
import { Callout } from "@/components/docs/callout";
import { Navigation } from "@/components/navigation";

<DocsLayout>
  <Navigation />

# Documentation

## Getting Started

Welcome to **scrap-ai**! This section is designed to help you set up and begin using the library quickly. Here, you'll find:

### Installation Instructions

To install scrap-ai, use your preferred package manager:

<CodeBlock language="bash">npm install scrap-ai@0.0.3</CodeBlock>

### Basic Configuration

After installation, you need to set up your API key:

<CodeBlock language="javascript">
import { ScrapeClient } from "scrap-ai";

const client = new ScrapeClient("YOUR_API_KEY");

</CodeBlock>

<Callout type="info">
  Replace "YOUR_API_KEY" with the API key you received upon registration.
</Callout>

### Quick Start Example

Here's a simple example to get you started with web scraping:

<CodeBlock language="javascript">
import { ScrapeClient } from "scrap-ai";

const client = new ScrapeClient("YOUR_API_KEY");

async function scrapeWebsite() {
try {
const result = await client.scrape(
"https://example.com",
"Extract all paragraph text",
"https://your-webhook-url.com/callback"
);
console.log("Scraping job initiated:", result.jobId);
} catch (error) {
console.error("Error:", error.message);
}
}

scrapeWebsite();

</CodeBlock>

This example initiates a scraping job for "https://example.com", extracting all paragraph text, and sends the results to your specified webhook URL.

## Using the Library

Once you have scrap-ai installed, dive into the rich set of features it offers. In this section, you'll discover:

### API Reference & Guides

#### ScrapeClient

The main class for interacting with the scrap-ai API.

<CodeBlock language="javascript">
class ScrapeClient {
  constructor(apiKey: string);
  scrape(url: string, instructions: string, webhookUrl: string): Promise<{ jobId: string }>;
  getJobStatus(jobId: string): Promise<{ status: string, progress: number }>;
}
</CodeBlock>

#### scrape(url, instructions, webhookUrl)

Initiates a scraping job.

- `url`: The target URL to scrape.
- `instructions`: Natural language instructions for the AI.
- `webhookUrl`: URL to receive the scraping results.

#### getJobStatus(jobId)

Retrieves the status of a scraping job.

- `jobId`: The ID of the job to check.

### Best Practices

1. **Rate Limiting**: Respect website's `robots.txt` and implement rate limiting to avoid overloading target servers.
2. **Error Handling**: Always wrap API calls in try-catch blocks to handle potential errors gracefully.
3. **Webhook Security**: Ensure your webhook endpoint is secure and validates incoming data.

### Use Case Examples

#### Scraping Product Information

<CodeBlock language="javascript">
const client = new ScrapeClient("YOUR_API_KEY");

async function scrapeProductInfo(productUrl) {
try {
const result = await client.scrape(
productUrl,
"Extract product name, price, and description",
"https://your-webhook-url.com/product-info"
);
console.log("Product info scraping initiated:", result.jobId);
} catch (error) {
console.error("Error scraping product info:", error.message);
}
}

scrapeProductInfo("https://example.com/product");

</CodeBlock>

#### Monitoring Job Progress

<CodeBlock language="javascript">
async function monitorJob(jobId) {
  try {
    const status = await client.getJobStatus(jobId);
    console.log(`Job ${jobId} status:`, status.status);
    console.log(`Progress: ${status.progress}%`);
  } catch (error) {
    console.error("Error checking job status:", error.message);
  }
}

monitorJob("job_123456");

</CodeBlock>

### Configuration Options

scrap-ai offers several configuration options to customize its behavior:

<CodeBlock language="javascript">
const client = new ScrapeClient("YOUR_API_KEY", {
  timeout: 30000, // Request timeout in milliseconds
  maxRetries: 3, // Maximum number of retries for failed requests
  userAgent: "Custom User Agent String", // Set a custom User-Agent header
});
</CodeBlock>

## Webhooks

Enhance your integration with real-time event handling using webhooks. In this section, you'll find:

### Setup Instructions

1. Configure your webhook URL in your scrap-ai dashboard or when initiating a scrape job.
2. Ensure your server is set up to receive POST requests at the specified URL.
3. Implement logic to handle and process the incoming webhook data.

### Event Triggers

Webhooks are triggered for the following events:

- `job.completed`: Fired when a scraping job is successfully completed.
- `job.failed`: Fired when a scraping job encounters an error and fails.
- `job.progress`: Fired periodically to update on the progress of a long-running job.

### Security Considerations

To secure your webhook endpoints:

1. Use HTTPS for your webhook URL to encrypt data in transit.
2. Implement webhook signature verification to ensure the authenticity of incoming requests.

<CodeBlock language="javascript">
const crypto = require('crypto');

function verifyWebhookSignature(payload, signature, secret) {
const hmac = crypto.createHmac('sha256', secret);
const digest = hmac.update(payload).digest('hex');
return crypto.timingSafeEqual(Buffer.from(signature), Buffer.from(digest));
}

</CodeBlock>

### Troubleshooting & Advanced Options

If you're not receiving webhook events:

1. Check that your webhook URL is correctly configured and accessible.
2. Verify that your server is properly handling POST requests.
3. Check your server logs for any errors in processing webhook data.

For advanced webhook configuration, you can:

- Set up retry logic for failed webhook deliveries.
- Implement a queueing system to handle high volumes of webhook events.

<Callout type="warning">
  Always handle webhook events idempotently, as the same event may be sent
  multiple times in rare cases.
</Callout>

</DocsLayout>
